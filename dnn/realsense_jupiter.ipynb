{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eade6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open3d\n",
      "  Obtaining dependency information for open3d from https://files.pythonhosted.org/packages/43/ee/1c0f25a57b43849fb9f1e773e5c065aa3363b49313bdbdfb7b35337bbab3/open3d-0.18.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading open3d-0.18.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from open3d) (1.24.3)\n",
      "Collecting dash>=2.6.0 (from open3d)\n",
      "  Obtaining dependency information for dash>=2.6.0 from https://files.pythonhosted.org/packages/b2/10/388c4a697275417a6974033e6ea7235d61e648e6c39d9cc06fcc6a6f71d4/dash-2.15.0-py3-none-any.whl.metadata\n",
      "  Downloading dash-2.15.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: werkzeug>=2.2.3 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from open3d) (2.2.3)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from open3d) (5.9.2)\n",
      "Collecting configargparse (from open3d)\n",
      "  Obtaining dependency information for configargparse from https://files.pythonhosted.org/packages/6f/b3/b4ac838711fd74a2b4e6f746703cf9dd2cf5462d17dac07e349234e21b97/ConfigArgParse-1.7-py3-none-any.whl.metadata\n",
      "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from open3d) (8.0.4)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (2.2.2)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (5.9.0)\n",
      "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (4.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (2.31.0)\n",
      "Collecting retrying (from dash>=2.6.0->open3d)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (1.5.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (68.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from dash>=2.6.0->open3d) (6.0.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (6.25.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.5)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from werkzeug>=2.2.3->open3d) (2.1.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.0.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (0.1.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (23.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (6.3.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=5.7.0->open3d) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=5.7.0->open3d) (305.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from retrying->dash>=2.6.0->open3d) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=8.0.4->open3d) (2.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Downloading open3d-0.18.0-cp311-cp311-win_amd64.whl (62.9 MB)\n",
      "   ---------------------------------------- 0.0/62.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/62.9 MB 960.0 kB/s eta 0:01:06\n",
      "   ---------------------------------------- 0.2/62.9 MB 1.9 MB/s eta 0:00:33\n",
      "   ---------------------------------------- 0.4/62.9 MB 3.1 MB/s eta 0:00:21\n",
      "    --------------------------------------- 0.8/62.9 MB 4.5 MB/s eta 0:00:14\n",
      "    --------------------------------------- 1.2/62.9 MB 5.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 2.5/62.9 MB 8.8 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 4.3/62.9 MB 11.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 7.8/62.9 MB 16.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 9.8/62.9 MB 17.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 11.7/62.9 MB 27.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 13.5/62.9 MB 27.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 14.3/62.9 MB 23.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 17.2/62.9 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 19.8/62.9 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 20.1/62.9 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 22.0/62.9 MB 27.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 24.7/62.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 26.7/62.9 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 29.3/62.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 30.2/62.9 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 32.5/62.9 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 33.0/62.9 MB 28.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 34.2/62.9 MB 27.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 35.2/62.9 MB 25.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 38.0/62.9 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 38.7/62.9 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 40.8/62.9 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 43.3/62.9 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 43.9/62.9 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 45.6/62.9 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 46.6/62.9 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 47.1/62.9 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 47.3/62.9 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 48.0/62.9 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 49.5/62.9 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 49.7/62.9 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 50.0/62.9 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 50.9/62.9 MB 12.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 51.5/62.9 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 51.6/62.9 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 53.4/62.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 55.0/62.9 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 55.9/62.9 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 57.8/62.9 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 60.5/62.9 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.8/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  62.9/62.9 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 62.9/62.9 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading dash-2.15.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.4/10.2 MB 44.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.1/10.2 MB 39.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.8/10.2 MB 38.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.4/10.2 MB 37.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.2 MB 37.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.2 MB 36.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 36.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 27.2 MB/s eta 0:00:00\n",
      "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, configargparse, dash, open3d\n",
      "Successfully installed configargparse-1.7 dash-2.15.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 open3d-0.18.0 retrying-1.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec0b733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\yashv\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\yashv\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ddb3bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyrealsense2\n",
      "  Obtaining dependency information for pyrealsense2 from https://files.pythonhosted.org/packages/68/de/794e449aff0faf8f38f9731e7ef78a088aec7d18926508d77e8563e28a88/pyrealsense2-2.54.2.5684-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pyrealsense2-2.54.2.5684-cp311-cp311-win_amd64.whl.metadata (1.9 kB)\n",
      "Downloading pyrealsense2-2.54.2.5684-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB 435.7 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.1/5.6 MB 939.4 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.3/5.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.6 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.5/5.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.6 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.2/5.6 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.9/5.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 10.2 MB/s eta 0:00:00\n",
      "Installing collected packages: pyrealsense2\n",
      "Successfully installed pyrealsense2-2.54.2.5684\n"
     ]
    }
   ],
   "source": [
    "!pip install pyrealsense2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7259b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Intel Realsense Camera\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 178\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Load Realsense camera\u001b[39;00m\n\u001b[0;32m    177\u001b[0m rs \u001b[38;5;241m=\u001b[39m RealsenseCamera()\n\u001b[1;32m--> 178\u001b[0m mrcnn \u001b[38;5;241m=\u001b[39m MaskRCNN()\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# Get frame in real time from Realsense camera\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     ret, bgr_frame, depth_frame \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_frame_stream()\n",
      "Cell \u001b[1;32mIn[11], line 69\u001b[0m, in \u001b[0;36mMaskRCNN.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124myashv\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownload\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmeasure_object_distance\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mclasses.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_object:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m file_object\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[0;32m     71\u001b[0m         class_name \u001b[38;5;241m=\u001b[39m class_name\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "class RealsenseCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        print(\"Loading Intel Realsense Camera\")\n",
    "        self.pipeline = rs.pipeline()\n",
    "\n",
    "        config = rs.config()\n",
    "        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "        align_to = rs.stream.color\n",
    "        self.align = rs.align(align_to)\n",
    "\n",
    "\n",
    "    def get_frame_stream(self):\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        aligned_frames = self.align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        \n",
    "        if not depth_frame or not color_frame:\n",
    "            # If there is no frame, probably camera not connected, return False\n",
    "            print(\"Error, impossible to get the frame, make sure that the Intel Realsense camera is correctly connected\")\n",
    "            return False, None, None\n",
    "        \n",
    "        # Apply filter to fill the Holes in the depth image\n",
    "        spatial = rs.spatial_filter()\n",
    "        spatial.set_option(rs.option.holes_fill, 3)\n",
    "        filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        filled_depth = hole_filling.process(filtered_depth)\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(filled_depth.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        return True, color_image, depth_image\n",
    "    \n",
    "    def release(self):\n",
    "        self.pipeline.stop()\n",
    "\n",
    "class MaskRCNN:\n",
    "    def __init__(self):\n",
    "        # Initialize MaskRCNN model here\n",
    "         # Loading Mask RCNN\n",
    "        self.net = cv2.dnn.readNetFromTensorflow(\"C:\\\\Users\\\\yashv\\\\Downloads\\\\measure_object_distance\\\\dnn\\\\frozen_inference_graph_coco.pb\",\n",
    "                                            \"C:\\\\Users\\\\yashv\\\\Downloads\\\\measure_object_distance\\\\dnn\\\\mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n",
    "        self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "        # Generate random colors\n",
    "        np.random.seed(2)\n",
    "        self.colors = np.random.randint(0, 255, (90, 3))\n",
    "\n",
    "        # Conf threshold\n",
    "        self.detection_threshold = 0.7\n",
    "        self.mask_threshold = 0.3\n",
    "\n",
    "        self.classes = []\n",
    "        with open(\"C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt\", \"r\") as file_object:\n",
    "            for class_name in file_object.readlines():\n",
    "                class_name = class_name.strip()\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "        self.obj_boxes = []\n",
    "        self.obj_classes = []\n",
    "        self.obj_centers = []\n",
    "        self.obj_contours = []\n",
    "\n",
    "        # Distances\n",
    "        self.distances = []\n",
    "\n",
    "    def detect_objects_mask(self, bgr_frame):\n",
    "        blob = cv2.dnn.blobFromImage(bgr_frame, swapRB=True)\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        boxes, masks = self.net.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "\n",
    "        # Detect objects\n",
    "        frame_height, frame_width, _ = bgr_frame.shape\n",
    "        detection_count = boxes.shape[2]\n",
    "\n",
    "        # Object Boxes\n",
    "        self.obj_boxes = []\n",
    "        self.obj_classes = []\n",
    "        self.obj_centers = []\n",
    "        self.obj_contours = []\n",
    "\n",
    "        for i in range(detection_count):\n",
    "            box = boxes[0, 0, i]\n",
    "            class_id = box[1]\n",
    "            score = box[2]\n",
    "            color = self.colors[int(class_id)]\n",
    "            if score < self.detection_threshold:\n",
    "                continue\n",
    "\n",
    "            # Get box Coordinates\n",
    "            x = int(box[3] * frame_width)\n",
    "            y = int(box[4] * frame_height)\n",
    "            x2 = int(box[5] * frame_width)\n",
    "            y2 = int(box[6] * frame_height)\n",
    "            self.obj_boxes.append([x, y, x2, y2])\n",
    "\n",
    "            cx = (x + x2) // 2\n",
    "            cy = (y + y2) // 2\n",
    "            self.obj_centers.append((cx, cy))\n",
    "\n",
    "            # append class\n",
    "            self.obj_classes.append(class_id)\n",
    "\n",
    "            # Contours\n",
    "            # Get mask coordinates\n",
    "            # Get the mask\n",
    "            mask = masks[i, int(class_id)]\n",
    "            roi_height, roi_width = y2 - y, x2 - x\n",
    "            mask = cv2.resize(mask, (roi_width, roi_height))\n",
    "            _, mask = cv2.threshold(mask, self.mask_threshold, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(np.array(mask, np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            self.obj_contours.append(contours)\n",
    "\n",
    "        return self.obj_boxes, self.obj_classes, self.obj_contours, self.obj_centers\n",
    "\n",
    "    def draw_object_mask(self, bgr_frame):\n",
    "        # loop through the detection\n",
    "        for box, class_id, contours in zip(self.obj_boxes, self.obj_classes, self.obj_contours):\n",
    "            x, y, x2, y2 = box\n",
    "            roi = bgr_frame[y: y2, x: x2]\n",
    "            roi_height, roi_width, _ = roi.shape\n",
    "            color = self.colors[int(class_id)]\n",
    "\n",
    "            roi_copy = np.zeros_like(roi)\n",
    "\n",
    "            for cnt in contours:\n",
    "                # cv2.f(roi, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "                cv2.drawContours(roi, [cnt], - 1, (int(color[0]), int(color[1]), int(color[2])), 3)\n",
    "                cv2.fillPoly(roi_copy, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "                roi = cv2.addWeighted(roi, 1, roi_copy, 0.5, 0.0)\n",
    "                bgr_frame[y: y2, x: x2] = roi\n",
    "        return bgr_frame\n",
    "\n",
    "    def draw_object_info(self, bgr_frame, depth_frame):\n",
    "        # loop through the detection\n",
    "        for box, class_id, obj_center in zip(self.obj_boxes, self.obj_classes, self.obj_centers):\n",
    "            x, y, x2, y2 = box\n",
    "\n",
    "            color = self.colors[int(class_id)]\n",
    "            color = (int(color[0]), int(color[1]), int(color[2]))\n",
    "\n",
    "            cx, cy = obj_center\n",
    "\n",
    "            depth_mm = depth_frame[cy, cx]\n",
    "\n",
    "            cv2.line(bgr_frame, (cx, y), (cx, y2), color, 1)\n",
    "            cv2.line(bgr_frame, (x, cy), (x2, cy), color, 1)\n",
    "\n",
    "            class_name = self.classes[int(class_id)]\n",
    "            cv2.rectangle(bgr_frame, (x, y), (x + 250, y + 70), color, -1)\n",
    "            cv2.putText(bgr_frame, class_name.capitalize(), (x + 5, y + 25), 0, 0.8, (255, 255, 255), 2)\n",
    "            cv2.putText(bgr_frame, \"{} cm\".format(depth_mm / 10), (x + 5, y + 60), 0, 1.0, (255, 255, 255), 2)\n",
    "            cv2.rectangle(bgr_frame, (x, y), (x2, y2), color, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return bgr_frame\n",
    "\n",
    "# Load Realsense camera\n",
    "rs = RealsenseCamera()\n",
    "mrcnn = MaskRCNN()\n",
    "\n",
    "while True:\n",
    "    # Get frame in real time from Realsense camera\n",
    "    ret, bgr_frame, depth_frame = rs.get_frame_stream()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get object mask\n",
    "    boxes, classes, contours, centers = mrcnn.detect_objects_mask(bgr_frame)\n",
    "\n",
    "    # Draw object mask\n",
    "    bgr_frame = mrcnn.draw_object_mask(bgr_frame)\n",
    "\n",
    "    # Show depth info of the objects\n",
    "    mrcnn.draw_object_info(bgr_frame, depth_frame)\n",
    "\n",
    "    # Visualize the depth frame\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points = np.zeros((depth_frame.shape[0] * depth_frame.shape[1], 3))\n",
    "    points[:, :2] = np.mgrid[0:depth_frame.shape[0], 0:depth_frame.shape[1]].reshape(2, -1).T\n",
    "    points[:, 2] = depth_frame.flatten()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "rs.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a44c6e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Intel Realsense Camera\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 207\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m#from realsense_camera import *\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m#from mask_rcnn import *\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Load Realsense camera\u001b[39;00m\n\u001b[0;32m    206\u001b[0m rs \u001b[38;5;241m=\u001b[39m RealsenseCamera()\n\u001b[1;32m--> 207\u001b[0m mrcnn \u001b[38;5;241m=\u001b[39m MaskRCNN()\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m \t\u001b[38;5;66;03m# Get frame in real time from Realsense camera\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \tret, bgr_frame, depth_frame \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_frame_stream()\n",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m, in \u001b[0;36mMaskRCNN.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124myashv\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownload\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmeasure_object_distance\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdnn\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mclasses.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_object:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m file_object\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[0;32m     24\u001b[0m         class_name \u001b[38;5;241m=\u001b[39m class_name\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt'"
     ]
    }
   ],
   "source": [
    "# https://pysource.com/instance-segmentation-mask-rcnn-with-python-and-opencv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class MaskRCNN:\n",
    "    def __init__(self):\n",
    "        # Loading Mask RCNN\n",
    "        self.net = cv2.dnn.readNetFromTensorflow(\"C:\\\\Users\\\\yashv\\\\Downloads\\\\measure_object_distance\\\\dnn\\\\frozen_inference_graph_coco.pb\",\n",
    "                                            \"C:\\\\Users\\\\yashv\\\\Downloads\\\\measure_object_distance\\\\dnn\\\\mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n",
    "        self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "        # Generate random colors\n",
    "        np.random.seed(2)\n",
    "        self.colors = np.random.randint(0, 255, (90, 3))\n",
    "\n",
    "        # Conf threshold\n",
    "        self.detection_threshold = 0.7\n",
    "        self.mask_threshold = 0.3\n",
    "\n",
    "        self.classes = []\n",
    "        with open('C:\\\\Users\\\\yashv\\\\Download\\\\measure_object_distance\\\\dnn\\\\classes.txt', \"r\") as file_object:\n",
    "            for class_name in file_object.readlines():\n",
    "                class_name = class_name.strip()\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "        self.obj_boxes = []\n",
    "        self.obj_classes = []\n",
    "        self.obj_centers = []\n",
    "        self.obj_contours = []\n",
    "\n",
    "        # Distances\n",
    "        self.distances = []\n",
    "\n",
    "\n",
    "    def detect_objects_mask(self, bgr_frame):\n",
    "        blob = cv2.dnn.blobFromImage(bgr_frame, swapRB=True)\n",
    "        self.net.setInput(blob)\n",
    "\n",
    "        boxes, masks = self.net.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "\n",
    "        # Detect objects\n",
    "        frame_height, frame_width, _ = bgr_frame.shape\n",
    "        detection_count = boxes.shape[2]\n",
    "\n",
    "        # Object Boxes\n",
    "        self.obj_boxes = []\n",
    "        self.obj_classes = []\n",
    "        self.obj_centers = []\n",
    "        self.obj_contours = []\n",
    "\n",
    "        for i in range(detection_count):\n",
    "            box = boxes[0, 0, i]\n",
    "            class_id = box[1]\n",
    "            score = box[2]\n",
    "            color = self.colors[int(class_id)]\n",
    "            if score < self.detection_threshold:\n",
    "                continue\n",
    "\n",
    "            # Get box Coordinates\n",
    "            x = int(box[3] * frame_width)\n",
    "            y = int(box[4] * frame_height)\n",
    "            x2 = int(box[5] * frame_width)\n",
    "            y2 = int(box[6] * frame_height)\n",
    "            self.obj_boxes.append([x, y, x2, y2])\n",
    "\n",
    "            cx = (x + x2) // 2\n",
    "            cy = (y + y2) // 2\n",
    "            self.obj_centers.append((cx, cy))\n",
    "\n",
    "            # append class\n",
    "            self.obj_classes.append(class_id)\n",
    "\n",
    "            # Contours\n",
    "            # Get mask coordinates\n",
    "            # Get the mask\n",
    "            mask = masks[i, int(class_id)]\n",
    "            roi_height, roi_width = y2 - y, x2 - x\n",
    "            mask = cv2.resize(mask, (roi_width, roi_height))\n",
    "            _, mask = cv2.threshold(mask, self.mask_threshold, 255, cv2.THRESH_BINARY)\n",
    "            contours, _ = cv2.findContours(np.array(mask, np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            self.obj_contours.append(contours)\n",
    "\n",
    "        return self.obj_boxes, self.obj_classes, self.obj_contours, self.obj_centers\n",
    "\n",
    "    def draw_object_mask(self, bgr_frame):\n",
    "        # loop through the detection\n",
    "        for box, class_id, contours in zip(self.obj_boxes, self.obj_classes, self.obj_contours):\n",
    "            x, y, x2, y2 = box\n",
    "            roi = bgr_frame[y: y2, x: x2]\n",
    "            roi_height, roi_width, _ = roi.shape\n",
    "            color = self.colors[int(class_id)]\n",
    "\n",
    "            roi_copy = np.zeros_like(roi)\n",
    "\n",
    "            for cnt in contours:\n",
    "                # cv2.f(roi, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "                cv2.drawContours(roi, [cnt], - 1, (int(color[0]), int(color[1]), int(color[2])), 3)\n",
    "                cv2.fillPoly(roi_copy, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "                roi = cv2.addWeighted(roi, 1, roi_copy, 0.5, 0.0)\n",
    "                bgr_frame[y: y2, x: x2] = roi\n",
    "        return bgr_frame\n",
    "\n",
    "    def draw_object_info(self, bgr_frame, depth_frame):\n",
    "        # loop through the detection\n",
    "        for box, class_id, obj_center in zip(self.obj_boxes, self.obj_classes, self.obj_centers):\n",
    "            x, y, x2, y2 = box\n",
    "\n",
    "            color = self.colors[int(class_id)]\n",
    "            color = (int(color[0]), int(color[1]), int(color[2]))\n",
    "\n",
    "            cx, cy = obj_center\n",
    "\n",
    "            depth_mm = depth_frame[cy, cx]\n",
    "\n",
    "            cv2.line(bgr_frame, (cx, y), (cx, y2), color, 1)\n",
    "            cv2.line(bgr_frame, (x, cy), (x2, cy), color, 1)\n",
    "\n",
    "            class_name = self.classes[int(class_id)]\n",
    "            cv2.rectangle(bgr_frame, (x, y), (x + 250, y + 70), color, -1)\n",
    "            cv2.putText(bgr_frame, class_name.capitalize(), (x + 5, y + 25), 0, 0.8, (255, 255, 255), 2)\n",
    "            cv2.putText(bgr_frame, \"{} cm\".format(depth_mm / 10), (x + 5, y + 60), 0, 1.0, (255, 255, 255), 2)\n",
    "            cv2.rectangle(bgr_frame, (x, y), (x2, y2), color, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return bgr_frame\n",
    "\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RealsenseCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        print(\"Loading Intel Realsense Camera\")\n",
    "        self.pipeline = rs.pipeline()\n",
    "\n",
    "        config = rs.config()\n",
    "        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "        align_to = rs.stream.color\n",
    "        self.align = rs.align(align_to)\n",
    "\n",
    "\n",
    "    def get_frame_stream(self):\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        aligned_frames = self.align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        \n",
    "        if not depth_frame or not color_frame:\n",
    "            # If there is no frame, probably camera not connected, return False\n",
    "            print(\"Error, impossible to get the frame, make sure that the Intel Realsense camera is correctly connected\")\n",
    "            return False, None, None\n",
    "        \n",
    "        # Apply filter to fill the Holes in the depth image\n",
    "        spatial = rs.spatial_filter()\n",
    "        spatial.set_option(rs.option.holes_fill, 3)\n",
    "        filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        filled_depth = hole_filling.process(filtered_depth)\n",
    "\n",
    "        \n",
    "        # Create colormap to show the depth of the Objects\n",
    "        colorizer = rs.colorizer()\n",
    "        depth_colormap = np.asanyarray(colorizer.colorize(filled_depth).get_data())\n",
    "\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        # distance = depth_frame.get_distance(int(50),int(50))\n",
    "        # print(\"distance\", distance)\n",
    "        depth_image = np.asanyarray(filled_depth.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # cv2.imshow(\"Colormap\", depth_colormap)\n",
    "        # cv2.imshow(\"depth img\", depth_image)\n",
    "\n",
    "        return True, color_image, depth_image\n",
    "    \n",
    "    def release(self):\n",
    "        self.pipeline.stop()\n",
    "        #print(depth_image)\n",
    "        \n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.10), 2)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        \n",
    "        #images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "\n",
    "#https://pysource.com\n",
    "import cv2\n",
    "#from realsense_camera import *\n",
    "#from mask_rcnn import *\n",
    "\n",
    "# Load Realsense camera\n",
    "rs = RealsenseCamera()\n",
    "mrcnn = MaskRCNN()\n",
    "\n",
    "while True:\n",
    "\t# Get frame in real time from Realsense camera\n",
    "\tret, bgr_frame, depth_frame = rs.get_frame_stream()\n",
    "\n",
    "\t# Get object mask\n",
    "\tboxes, classes, contours, centers = mrcnn.detect_objects_mask(bgr_frame)\n",
    "\n",
    "\t# Draw object mask\n",
    "\tbgr_frame = mrcnn.draw_object_mask(bgr_frame)\n",
    "\n",
    "\t# Show depth info of the objects\n",
    "\tmrcnn.draw_object_info(bgr_frame, depth_frame)\n",
    "\n",
    "\n",
    "\tcv2.imshow(\"depth frame\", depth_frame)\n",
    "\tcv2.imshow(\"Bgr frame\", bgr_frame)\n",
    "\n",
    "\tkey = cv2.waitKey(1)\n",
    "\tif key == 27:\n",
    "\t\tbreak\n",
    "\n",
    "rs.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a26b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pysource.com\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RealsenseCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        print(\"Loading Intel Realsense Camera\")\n",
    "        self.pipeline = rs.pipeline()\n",
    "\n",
    "        config = rs.config()\n",
    "        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "        align_to = rs.stream.color\n",
    "        self.align = rs.align(align_to)\n",
    "\n",
    "\n",
    "    def get_frame_stream(self):\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        aligned_frames = self.align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        \n",
    "        if not depth_frame or not color_frame:\n",
    "            # If there is no frame, probably camera not connected, return False\n",
    "            print(\"Error, impossible to get the frame, make sure that the Intel Realsense camera is correctly connected\")\n",
    "            return False, None, None\n",
    "        \n",
    "        # Apply filter to fill the Holes in the depth image\n",
    "        spatial = rs.spatial_filter()\n",
    "        spatial.set_option(rs.option.holes_fill, 3)\n",
    "        filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        filled_depth = hole_filling.process(filtered_depth)\n",
    "\n",
    "        \n",
    "        # Create colormap to show the depth of the Objects\n",
    "        colorizer = rs.colorizer()\n",
    "        depth_colormap = np.asanyarray(colorizer.colorize(filled_depth).get_data())\n",
    "\n",
    "        \n",
    "        # Convert images to numpy arrays\n",
    "        # distance = depth_frame.get_distance(int(50),int(50))\n",
    "        # print(\"distance\", distance)\n",
    "        depth_image = np.asanyarray(filled_depth.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        # cv2.imshow(\"Colormap\", depth_colormap)\n",
    "        # cv2.imshow(\"depth img\", depth_image)\n",
    "\n",
    "        return True, color_image, depth_image\n",
    "    \n",
    "    def release(self):\n",
    "        self.pipeline.stop()\n",
    "        #print(depth_image)\n",
    "        \n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.10), 2)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "        \n",
    "        #images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db5f201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Intel Realsense Camera\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'pyrealsense2.pyrealsense2.pipeline' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from realsense_camera import *\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#from mask_rcnn import *\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load Realsense camera\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m rs \u001b[38;5;241m=\u001b[39m RealsenseCamera()\n\u001b[0;32m      8\u001b[0m mrcnn \u001b[38;5;241m=\u001b[39m MaskRCNN()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m \t\u001b[38;5;66;03m# Get frame in real time from Realsense camera\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mRealsenseCamera.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Configure depth and color streams\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Intel Realsense Camera\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mpipeline()\n\u001b[0;32m     12\u001b[0m     config \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mconfig()\n\u001b[0;32m     13\u001b[0m     config\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mcolor, \u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m720\u001b[39m, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mbgr8, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'pyrealsense2.pyrealsense2.pipeline' object is not callable"
     ]
    }
   ],
   "source": [
    "#https://pysource.com\n",
    "import cv2\n",
    "#from realsense_camera import *\n",
    "#from mask_rcnn import *\n",
    "\n",
    "# Load Realsense camera\n",
    "rs = RealsenseCamera()\n",
    "mrcnn = MaskRCNN()\n",
    "\n",
    "while True:\n",
    "\t# Get frame in real time from Realsense camera\n",
    "\tret, bgr_frame, depth_frame = rs.get_frame_stream()\n",
    "\n",
    "\t# Get object mask\n",
    "\tboxes, classes, contours, centers = mrcnn.detect_objects_mask(bgr_frame)\n",
    "\n",
    "\t# Draw object mask\n",
    "\tbgr_frame = mrcnn.draw_object_mask(bgr_frame)\n",
    "\n",
    "\t# Show depth info of the objects\n",
    "\tmrcnn.draw_object_info(bgr_frame, depth_frame)\n",
    "\n",
    "\n",
    "\tcv2.imshow(\"depth frame\", depth_frame)\n",
    "\tcv2.imshow(\"Bgr frame\", bgr_frame)\n",
    "\n",
    "\tkey = cv2.waitKey(1)\n",
    "\tif key == 27:\n",
    "\t\tbreak\n",
    "\n",
    "rs.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "924217a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement realsense_camera (from versions: none)\n",
      "ERROR: No matching distribution found for realsense_camera\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a57e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
